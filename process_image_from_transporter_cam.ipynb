{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa93e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from cv2 import aruco\n",
    "import math\n",
    "import shutil\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pyquaternion import Quaternion\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ee3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transporter:\n",
    "    def __init__(self):\n",
    "        self.aruco_dict = cv2.aruco.getPredefinedDictionary(aruco.DICT_6X6_250)\n",
    "        self.parameters = cv2.aruco.DetectorParameters()\n",
    "        self.ar_detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.parameters)\n",
    "\n",
    "    def estimate_arucos_poses(\n",
    "        self, \n",
    "        image,\n",
    "        intrinsic,\n",
    "        distortion_coef,\n",
    "        marker_sizes,\n",
    "        aruco_corners,\n",
    "        correct_rot_mat=np.eye(3)):\n",
    "        \"\"\"\n",
    "        Estimate the pose of ArUco markers in the image.\n",
    "        Parameters:\n",
    "            image: Input image containing ArUco markers.\n",
    "            intrinsic: Camera intrinsic matrix.\n",
    "            distortion_coef: Distortion coefficients of the camera.\n",
    "            marker_sizes: Size of the ArUco marker in meters.\n",
    "            aruco_corners: Detected corners of the ArUco markers.\n",
    "            correct_rot_mat: Rotation matrix to correct the orientation of the markers.\n",
    "        Returns:\n",
    "            rvecs: List of rotation vectors for each detected marker.\n",
    "            tvecs: List of translation vectors for each detected marker.\n",
    "        \"\"\"\n",
    "\n",
    "        rvecs, tvecs = [], [] \n",
    "    \n",
    "        for i in range(len(aruco_corners)):\n",
    "            marker_size = marker_sizes[i]\n",
    "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(\n",
    "                aruco_corners[i], \n",
    "                marker_size, \n",
    "                intrinsic, \n",
    "                distortion_coef)\n",
    "            r_mat, _ = cv2.Rodrigues(rvec)\n",
    "    \n",
    "            # The aruco is rotated about z-axis, we need to adjust the rotation matrix. If \n",
    "            # it is pasted correctly, just multiply with identity matrix.\n",
    "            r_mat_correct = r_mat @ correct_rot_mat\n",
    "            r_vec_correct, _ = cv2.Rodrigues(r_mat_correct)\n",
    "    \n",
    "            rvecs.append(r_vec_correct)\n",
    "            tvecs.append(tvec)\n",
    "                 \n",
    "        return rvecs, tvecs\n",
    "\n",
    "    def detect_aruco_markers_by_id(\n",
    "        self, \n",
    "        image,\n",
    "        selected_aruco_ids,\n",
    "        BGR_format=True):\n",
    "        \"\"\"\n",
    "        Detect ArUco markers in the image by their IDs.\n",
    "        Parameters:\n",
    "            image: Input image containing ArUco markers.\n",
    "            selected_aruco_ids: List of ArUco marker IDs to detect.\n",
    "            BGR_format: If True, the input image is in BGR format, otherwise RGB.\n",
    "        Returns:\n",
    "            boxes: List of bounding boxes for detected markers.\n",
    "            centers: List of centers of the detected markers.\n",
    "            detected_corners: List of corners for the detected markers.\n",
    "            detected_aruco_ids: List of IDs of the detected markers.\n",
    "        \"\"\"\n",
    "\n",
    "        boxes = []\n",
    "        centers = []\n",
    "        detected_corners = []\n",
    "        detected_aruco_ids = []\n",
    "        gray_img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        corners, ids, _ = self.ar_detector.detectMarkers(gray_img)\n",
    "\n",
    "        if ids is None:\n",
    "            return boxes, centers, detected_corners, detected_aruco_ids\n",
    "            \n",
    "        for i, marker_id in enumerate(ids.flatten()):\n",
    "            if marker_id in selected_aruco_ids:\n",
    "                x_coords = corners[i][0][:, 0]\n",
    "                y_coords = corners[i][0][:, 1]\n",
    "                x1, y1 = int(np.min(x_coords)), int(np.min(y_coords))\n",
    "                x2, y2 = int(np.max(x_coords)), int(np.max(y_coords))\n",
    "                center = ((x1+x2)//2, (y1+y2)//2)\n",
    "                boxes.append(((x1, y1, x2, y2), f'ArUco_{marker_id}', 1.0))\n",
    "                centers.append(center)\n",
    "                detected_corners.append(corners[i])\n",
    "                detected_aruco_ids.append(marker_id)\n",
    "                \n",
    "        return boxes, centers, detected_corners, detected_aruco_ids\n",
    "\n",
    "    def calculate_add_on_length(self, carried_object_length):\n",
    "        \"\"\"\n",
    "        Suppose that transporter is able to align in the middle of the carried object\n",
    "        \"\"\"\n",
    "        assert carried_object_length > self.transporter_length\n",
    "        return (carried_object_length - self.transporter_length) / 2\n",
    "\n",
    "    def draw_aruco_poses(\n",
    "        self,\n",
    "        image, \n",
    "        markers_corners, \n",
    "        matrix_coefficients,\n",
    "        distortion_coefficients,\n",
    "        rvecs,\n",
    "        tvecs):\n",
    "    \n",
    "        annotated_image = image.copy()\n",
    "    \n",
    "        for rvec, tvec in zip(rvecs, tvecs):\n",
    "            annotated_image = cv2.drawFrameAxes(\n",
    "                annotated_image, \n",
    "                matrix_coefficients, \n",
    "                distortion_coefficients, \n",
    "                rvec, \n",
    "                tvec, \n",
    "                length=0.06) \n",
    "    \n",
    "        return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108db777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeWithCropFactor(img, size, intrinsic=None):\n",
    "    h1, w1 = img.shape[:2]\n",
    "    w2, h2 = size\n",
    "    if h1 == h2 and w1 == w2:\n",
    "        return img, intrinsic \n",
    "    r1 = w1 / h1\n",
    "    r2 = w2 / h2\n",
    "    if r1 >= r2:\n",
    "        changed_width = int(r2 * h1)\n",
    "        offset_pxl_pos = int((w1 - changed_width) / 2)\n",
    "        img = img[:, offset_pxl_pos : offset_pxl_pos + changed_width]\n",
    "        ratio = h2 / h1\n",
    "    elif r1 < r2:\n",
    "        changed_height = int(w1 / r2)\n",
    "        offset_pxl_pos = int((h1 - changed_height) / 2)\n",
    "        img = img[offset_pxl_pos : offset_pxl_pos + changed_height, :]\n",
    "        ratio = w2 / w1\n",
    "\n",
    "    if intrinsic is not None:\n",
    "        cx = w2 / 2\n",
    "        cy = h2 / 2\n",
    "\n",
    "        new_intrinsic = intrinsic.copy()\n",
    "        new_intrinsic[0, -1] = cx\n",
    "        new_intrinsic[1, -1] = cy\n",
    "        new_intrinsic[0, 0] *= ratio\n",
    "        new_intrinsic[1, 1] *= ratio\n",
    "        return cv2.resize(img, (w2, h2)), new_intrinsic\n",
    "\n",
    "    return cv2.resize(img, (w2, h2)), None\n",
    "\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "    \"\"\"\n",
    "    Convert a rotation matrix to Euler angles (roll, pitch, yaw).\n",
    "    \"\"\"\n",
    "    assert (R.shape == (3, 3))\n",
    "    \n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    \n",
    "    singular = sy < 1e-6\n",
    "    \n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    \n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def compute_angle(rmat):\n",
    "    \"\"\"Computes the angle from the rotation vector.\"\"\"\n",
    "    #euler_angles = rotationMatrixToEulerAngles(rmat)\n",
    "    #angle = np.rad2deg(euler_angles)[1]\n",
    "    #angle = -angle\n",
    "    #return angle\n",
    "\n",
    "    degrees = R.from_matrix(rmat).as_euler('yxz', degrees=True)\n",
    "    pitch_angle = degrees[0]\n",
    "    sign = int(np.sign(pitch_angle))\n",
    "    angle = abs(pitch_angle)\n",
    "    pitch_angle = (180. - angle) * -sign\n",
    "    return pitch_angle\n",
    "\n",
    "def put_text(\n",
    "    image, \n",
    "    device_depth=None, \n",
    "    device_angle=None, \n",
    "    device_shift=None):\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "    midpoint = (annotated_image.shape[1] // 2, annotated_image.shape[0] // 2)\n",
    "\n",
    "    text_lines = [\n",
    "        f\"Depth: {device_depth:.2f} m\",\n",
    "        f\"Angle: {device_angle:.2f} deg\",\n",
    "        f\"Shift: ({device_shift[0]:.2f} m, {device_shift[1]:.2f}) m\"]\n",
    "\n",
    "    y_offset = 40\n",
    "    for line in text_lines:\n",
    "        text_size = cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "        cv2.putText(annotated_image, line, \n",
    "                (midpoint[0], midpoint[1]-y_offset),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        y_offset += text_size[1] + 10\n",
    "\n",
    "    return annotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227e952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root /home/alan_khang/Desktop/adam_dataset/t2_2025_08_03 does not exist.\n"
     ]
    }
   ],
   "source": [
    "src_dirs = []\n",
    "\n",
    "root_dir = '/home/alan_khang/Desktop/adam_dataset'\n",
    "transporter_name = ['t1', 't2']\n",
    "#date_dir = ['2025_07_25', '2025_07_29', '2025_07_30', '2025_07_31', '2025_08_01']\n",
    "date_dir = ['2025_08_03']\n",
    "\n",
    "for transporter in transporter_name:\n",
    "    for date in date_dir:\n",
    "        dataset_root = osp.join(root_dir, f'{transporter}_{date}')\n",
    "        if not osp.exists(dataset_root):\n",
    "            print(f\"Dataset root {dataset_root} does not exist.\")\n",
    "            continue\n",
    "        scenes_by_date = sorted(os.listdir(dataset_root))\n",
    "        scenes_by_date = list(filter(lambda x: date in x, scenes_by_date))\n",
    "        scenes_by_date = [osp.join(dataset_root, s) for s in scenes_by_date]\n",
    "        scenes_by_date = [s for s in scenes_by_date if osp.isdir(s)]\n",
    "        src_dirs.extend(scenes_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8962bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_id_by_side = {\n",
    "    'bottom': [2],\n",
    "    'right': [6, 9],\n",
    "    'left': [5, 4],\n",
    "    'front': [7, 8]\n",
    "}\n",
    "\n",
    "aruco_size_by_id = {\n",
    "    2: 0.049,  # Bottom marker\n",
    "    6: 0.046,  # Right markers\n",
    "    9: 0.046,  # Right markers \n",
    "    7: 0.046,  # Front markers\n",
    "    8: 0.046,  # Front markers\n",
    "    5: 0.046,  # Left markers\n",
    "    4: 0.042   # Left markers\n",
    "}\n",
    "\n",
    "guilder_aruco_2_center_mat_filepath = '/home/alan_khang/Desktop/adam_dataset/guilder_aruco_2_center_mat.json'\n",
    "\n",
    "with open(guilder_aruco_2_center_mat_filepath, 'r') as f:\n",
    "    guilder_aruco_2_center_mat_dict = json.load(f)\n",
    "\n",
    "aruco_2_center_mat = {\n",
    "    2: np.array(guilder_aruco_2_center_mat_dict['bottom_aruco_pose_2_global_pose'], dtype=np.float64),\n",
    "    6: np.array(guilder_aruco_2_center_mat_dict['aruco_id_6_2_global_pose'], dtype=np.float64),\n",
    "    9: np.array(guilder_aruco_2_center_mat_dict['aruco_id_9_2_global_pose'], dtype=np.float64),\n",
    "    5: np.array(guilder_aruco_2_center_mat_dict['aruco_id_5_2_global_pose'], dtype=np.float64),\n",
    "    4: np.array(guilder_aruco_2_center_mat_dict['aruco_id_4_2_global_pose'], dtype=np.float64),\n",
    "    7: np.array(guilder_aruco_2_center_mat_dict['aruco_id_7_2_global_pose'], dtype=np.float64),\n",
    "    8: np.array(guilder_aruco_2_center_mat_dict['aruco_id_8_2_global_pose'], dtype=np.float64) \n",
    "}\n",
    "\n",
    "aruco_ids_to_detect = list(aruco_2_center_mat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3bb2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:06<00:00, 30.72it/s]\n",
      "100%|██████████| 491/491 [00:15<00:00, 32.22it/s]\n"
     ]
    }
   ],
   "source": [
    "offset_px = 5\n",
    "\n",
    "correct_rot_mat = np.eye(3)\n",
    "\n",
    "overlay_color = [0, 0, 0]\n",
    "\n",
    "target_marker_ids = [2]\n",
    "\n",
    "guilder_width = 0.58\n",
    "guilder_height = 0.304\n",
    "guilder_length = 0.488\n",
    "\n",
    "distance_between_ground_and_bottom_aruco = 0.094\n",
    "distance_between_guilder_rear_and_bottom_aruco = 0.04\n",
    "\n",
    "guilder_whl = np.array([guilder_width, guilder_height, guilder_length])\n",
    "\n",
    "guilder_center_coord_in_aruco_coord = np.array([\n",
    "    [1., 0., 0., 0.],\n",
    "    [0., 1., 0., (guilder_height / 2) - distance_between_ground_and_bottom_aruco],  \n",
    "    [0., 0., 1., -((guilder_length / 2) - distance_between_guilder_rear_and_bottom_aruco)],   \n",
    "    [0., 0., 0., 1.]], dtype=np.float32)\n",
    "\n",
    "annotated_img_dir_name = 'processed/annotated_images'\n",
    "annotated_dir_name = 'processed/annotations'\n",
    "img_dir_name = 'processed/images'\n",
    "\n",
    "transporter = Transporter()\n",
    "\n",
    "for src_dir in src_dirs:\n",
    "    raw_color_dir = os.path.join(src_dir, 'color')\n",
    "    annotated_img_dir = os.path.join(src_dir, annotated_img_dir_name)\n",
    "    annotated_dir = os.path.join(src_dir, annotated_dir_name)\n",
    "    img_dir = os.path.join(src_dir, img_dir_name) \n",
    "\n",
    "    if os.path.exists(annotated_img_dir):\n",
    "        shutil.rmtree(annotated_img_dir)\n",
    "\n",
    "    if os.path.exists(annotated_dir):\n",
    "        shutil.rmtree(annotated_dir)\n",
    "\n",
    "    if os.path.exists(img_dir):\n",
    "        shutil.rmtree(img_dir)\n",
    "\n",
    "    os.makedirs(annotated_img_dir, exist_ok=True)\n",
    "    os.makedirs(annotated_dir, exist_ok=True)\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "    img_paths = sorted(glob.glob(os.path.join(raw_color_dir, '*.jpg')))\n",
    "    for img_path in tqdm(img_paths):\n",
    "        try: \n",
    "            json_path = img_path.replace('color', 'info').replace('.jpg', '.json')\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"JSON file {json_path} does not exist. Skipping.\")\n",
    "                continue\n",
    "            with open(json_path, 'r') as f:\n",
    "                img_info = json.load(f)\n",
    "            img_filename = os.path.basename(img_path)\n",
    "            intr = np.array(img_info['camera_intrinsic'], dtype=np.float32)\n",
    "            color_wh = (img_info['image_size']['width'], img_info['image_size']['height'])\n",
    "            expected_size = (img_info['depth_size']['width'], img_info['depth_size']['height'])\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img.shape[:2][::-1] != color_wh:\n",
    "                raise ValueError(\n",
    "                    f\"Image {img_filename} has unexpected size {img.shape[:2][::-1]}, expected {color_wh}.\")\n",
    "\n",
    "            img, intr = resizeWithCropFactor(img, expected_size, intrinsic=np.array(intr, dtype=np.float32))\n",
    "            resized_img = img.copy()\n",
    "\n",
    "            (aruco_boxes, aruco_centers, \n",
    "            aruco_detected_corners, aruco_detected_ids) = transporter.detect_aruco_markers_by_id(\n",
    "                resized_img, \n",
    "                aruco_ids_to_detect,\n",
    "                BGR_format=True)\n",
    "            num_markers = len(aruco_centers)\n",
    "\n",
    "            if num_markers == 0:\n",
    "                #print(f\"No ArUco markers detected in {img_filename}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            markers_sizes = [aruco_size_by_id[id] for id in aruco_detected_ids]\n",
    "            processed_img = np.ascontiguousarray(img.copy())\n",
    "            rvecs, tvecs = transporter.estimate_arucos_poses(\n",
    "                processed_img, \n",
    "                intr, \n",
    "                np.zeros(8, dtype=np.float64),\n",
    "                markers_sizes, \n",
    "                aruco_detected_corners)\n",
    "\n",
    "            assert len(rvecs) == len(aruco_detected_ids)\n",
    "\n",
    "            cam_2_global_poses_in_frame = []\n",
    "            aruco_detected = dict()\n",
    "\n",
    "            for rvec, tvec, aruco_id, aruco_corners in zip(rvecs, tvecs, aruco_detected_ids, aruco_detected_corners):\n",
    "                if rvec is None or tvec is None:\n",
    "                    print(f\"Skipping marker {aruco_id} due to None rvec or tvec.\")\n",
    "                    continue\n",
    "                rmat, _ = cv2.Rodrigues(rvec)\n",
    "                cam_2_aruco_quat = R.from_matrix(rmat).as_quat(scalar_first=True)\n",
    "                cam_2_aruco_pose = np.eye(4, dtype=np.float32)\n",
    "                cam_2_aruco_pose[:3, :3] = rmat\n",
    "                cam_2_aruco_pose[:3, 3] = tvec.flatten()\n",
    "\n",
    "                aruco_pose_2_global_pose = aruco_2_center_mat[aruco_id]\n",
    "                cam_2_global_pose = cam_2_aruco_pose @ aruco_pose_2_global_pose\n",
    "\n",
    "                cam_2_global_poses_in_frame.append(cam_2_global_pose)\n",
    "\n",
    "                aruco_box = aruco_corners[0].astype(np.int16).squeeze()\n",
    "                box_xyxy = [int(np.min(aruco_box[:, 0])), int(np.min(aruco_box[:, 1])),\n",
    "                            int(np.max(aruco_box[:, 0])), int(np.max(aruco_box[:, 1]))]\n",
    "                aruco_detected[str(aruco_id)] = {\n",
    "                    'rot': cam_2_aruco_quat.tolist(),\n",
    "                    'trans': tvec.flatten().tolist(),\n",
    "                    'box_2d_xyxy': box_xyxy,\n",
    "                    'aruco_2_global_rot': aruco_pose_2_global_pose.tolist()}\n",
    "\n",
    "            assert len(cam_2_global_poses_in_frame) > 0\n",
    "            translations = np.array([T[:3, 3] for T in cam_2_global_poses_in_frame])\n",
    "            avg_translation = np.mean(translations, axis=0)\n",
    "\n",
    "            # Average rotation using quaternions\n",
    "            rotations = R.from_matrix([T[:3, :3] for T in cam_2_global_poses_in_frame])\n",
    "            avg_rotation = R.mean(rotations).as_matrix()\n",
    "        \n",
    "            cam_2_global_pose_avg = np.eye(4)\n",
    "            cam_2_global_pose_avg[:3, :3] = avg_rotation\n",
    "            cam_2_global_pose_avg[:3, 3] = avg_translation\n",
    "\n",
    "            guilder_angle = compute_angle(avg_rotation)\n",
    "\n",
    "            annotated_rgb = transporter.draw_aruco_poses(\n",
    "               processed_img, \n",
    "               aruco_detected_corners, \n",
    "               intr, \n",
    "               np.zeros(8, dtype=np.float64),\n",
    "               rvecs, \n",
    "               tvecs)\n",
    "\n",
    "            annotated_rgb = put_text(\n",
    "               annotated_rgb,\n",
    "               device_depth=round(avg_translation[2], 4),\n",
    "               device_angle=guilder_angle,\n",
    "               device_shift=(round(avg_translation[0], 4), \n",
    "                             round(avg_translation[1], 4)))\n",
    "\n",
    "            for aruco_corners in aruco_detected_corners:\n",
    "               aruco_box = aruco_corners[0].astype(np.int16).squeeze()\n",
    "               box_xyxy = [int(np.min(aruco_box[:, 0])), int(np.min(aruco_box[:, 1])),\n",
    "                           int(np.max(aruco_box[:, 0])), int(np.max(aruco_box[:, 1]))]\n",
    "\n",
    "               resized_img = cv2.rectangle(\n",
    "                   resized_img, \n",
    "                   (box_xyxy[0] - offset_px, box_xyxy[1] - offset_px), \n",
    "                   (box_xyxy[2] + offset_px, box_xyxy[3] + offset_px), \n",
    "                   overlay_color[::-1],\n",
    "                   thickness=-1)\n",
    "\n",
    "            cv2.imwrite(\n",
    "               os.path.join(annotated_img_dir, img_filename), \n",
    "               annotated_rgb)\n",
    "\n",
    "            cv2.imwrite(\n",
    "               os.path.join(img_dir, img_filename), \n",
    "               resized_img)\n",
    "\n",
    "            guilder_center = cam_2_global_pose_avg[:3, 3]\n",
    "            guilder_rot_mat = cam_2_global_pose_avg[:3, :3]\n",
    "            guilder_rot_quat = R.from_matrix(guilder_rot_mat).as_quat(scalar_first=True)\n",
    "\n",
    "            annot = {\n",
    "               'camera_intrinsic': intr.tolist(),\n",
    "               'aruco_detected': aruco_detected,\n",
    "               #'aruco_center': aruco_center.tolist(),\n",
    "               #'aruco_orientation': aruco_orientation.tolist(),\n",
    "               #'aruco_pitch_deg': aruco_pitch,\n",
    "               #'aruco_pitch_rad': math.radians(aruco_pitch),\n",
    "               'guilder_whl': guilder_whl.tolist(),\n",
    "               'guilder_center': guilder_center.tolist(),\n",
    "               'guilder_pitch_deg': guilder_angle,\n",
    "               'guilder_pitch_rad': math.radians(guilder_angle),\n",
    "               'guilder_rot': guilder_rot_quat.tolist(),\n",
    "               'timestamp': img_info['timestamp'],\n",
    "               'img_width': expected_size[0],\n",
    "               'img_height': expected_size[1]\n",
    "            }\n",
    "\n",
    "            assert img_filename.endswith('.jpg')\n",
    "            json_path = os.path.join(annotated_dir, img_filename.replace('.jpg', '.json'))\n",
    "\n",
    "            with open(json_path, 'w') as f:\n",
    "               json.dump(annot, f, indent=4)\n",
    "\n",
    "            #aruco_boxes, aruco_centers, aruco_selected_corners = transporter.detect_aruco_markers_by_id(\n",
    "                #img, \n",
    "                #target_marker_ids, \n",
    "                #BGR_format=True)\n",
    "            #num_markers = len(aruco_centers)\n",
    "\n",
    "            #if num_markers >= 1:\n",
    "                #processed_img = np.ascontiguousarray(img.copy())\n",
    "                #marker_size = 0.049\n",
    "                #rvecs, tvecs = transporter.estimate_arucos_poses(\n",
    "                    #processed_img, \n",
    "                    #intr, \n",
    "                    #np.zeros(8, dtype=np.float64),\n",
    "                    #marker_size, \n",
    "                    #aruco_selected_corners, \n",
    "                    #correct_rot_mat=correct_rot_mat)\n",
    "\n",
    "                #if num_markers == 1:\n",
    "                    #tvec, rvec = tvecs[0], rvecs[0]\n",
    "                    #t_mid = tvec\n",
    "                    #R_mid, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "                #if R_mid is not None and t_mid is not None:\n",
    "                    #device_angle = compute_angle(R_mid)\n",
    "\n",
    "                    #object_center = intr @ t_mid.squeeze().reshape(3, 1)\n",
    "                    #object_center_2d = object_center / object_center[2]  # Normalize by the third coordinate\n",
    "                    #object_center_2d = object_center_2d[:2].flatten() \n",
    "                    #device_midpoint = (int(object_center_2d[0]), int(object_center_2d[1]))\n",
    "\n",
    "                    #aruco_coord_in_camera = np.eye(4)\n",
    "                    #aruco_coord_in_camera[:3, :3] = R_mid\n",
    "                    #aruco_coord_in_camera[:3, 3] = t_mid.squeeze() \n",
    "\n",
    "                    #guilder_center_coord_in_cam = aruco_coord_in_camera @ guilder_center_coord_in_aruco_coord\n",
    "\n",
    "                    #aruco_orientation = R.from_matrix(R_mid).as_quat(scalar_first=True)\n",
    "                    #aruco_center = np.array([\n",
    "                        #round(aruco_coord_in_camera[0, 3], 8),\n",
    "                        #round(aruco_coord_in_camera[1, 3], 8),\n",
    "                        #round(aruco_coord_in_camera[2, 3], 8)\n",
    "                    #])\n",
    "                    #aruco_pitch = device_angle\n",
    "\n",
    "                    #guilder_center = guilder_center_coord_in_cam[:-1, -1]\n",
    "\n",
    "                    #annotated_rgb = _draw_boxes_and_labels(\n",
    "                        #processed_img, \n",
    "                        #aruco_selected_corners, \n",
    "                        #intr, \n",
    "                        #np.zeros(8, dtype=np.float64),\n",
    "                        #rvecs, \n",
    "                        #tvecs, \n",
    "                        #device_depth=round(aruco_coord_in_camera[2, 3], 4), \n",
    "                        #device_angle=device_angle, \n",
    "                        #device_shift=(round(aruco_coord_in_camera[0, 3], 4), round(aruco_coord_in_camera[1, 3], 4)), \n",
    "                        #midpoint=device_midpoint)\n",
    "\n",
    "                    #for aruco_corners in aruco_selected_corners:\n",
    "                        #aruco_box = aruco_corners[0].astype(np.int16).squeeze()\n",
    "                        #box_xyxy = [int(np.min(aruco_box[:, 0])), int(np.min(aruco_box[:, 1])),\n",
    "                                    #int(np.max(aruco_box[:, 0])), int(np.max(aruco_box[:, 1]))]\n",
    "\n",
    "                        #resized_img = cv2.rectangle(\n",
    "                            #resized_img, \n",
    "                            #(box_xyxy[0] - offset_px, box_xyxy[1] - offset_px), \n",
    "                            #(box_xyxy[2] + offset_px, box_xyxy[3] + offset_px), \n",
    "                            #overlay_color[::-1],\n",
    "                            #thickness=-1)\n",
    "\n",
    "                    #cv2.imwrite(\n",
    "                        #os.path.join(annotated_img_dir, img_filename), \n",
    "                        #annotated_rgb)\n",
    "\n",
    "                    #cv2.imwrite(\n",
    "                        #os.path.join(img_dir, img_filename), \n",
    "                        #resized_img)\n",
    "\n",
    "                    #annot = {\n",
    "                        #'camera_intrinsic': intr.tolist(),\n",
    "                        #'aruco_center': aruco_center.tolist(),\n",
    "                        #'aruco_orientation': aruco_orientation.tolist(),\n",
    "                        #'aruco_pitch_deg': aruco_pitch,\n",
    "                        #'aruco_pitch_rad': math.radians(aruco_pitch),\n",
    "                        #'guilder_whl': guilder_whl.tolist(),\n",
    "                        #'guilder_center': guilder_center.tolist(),\n",
    "                        #'timestamp': img_info['timestamp'],\n",
    "                        #'img_width': expected_size[0],\n",
    "                        #'img_height': expected_size[1]\n",
    "                    #}\n",
    "\n",
    "                    #assert img_filename.endswith('.jpg')\n",
    "                    #json_path = os.path.join(annotated_dir, img_filename.replace('.jpg', '.json'))\n",
    "\n",
    "                    #with open(json_path, 'w') as f:\n",
    "                        #json.dump(annot, f, indent=4)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_filename}: {e}\")\n",
    "            shutil.rmtree(img_dir)\n",
    "            shutil.rmtree(annotated_img_dir)\n",
    "            shutil.rmtree(annotated_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928353b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adam_et",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
